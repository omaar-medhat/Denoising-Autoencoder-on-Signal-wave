# -*- coding: utf-8 -*-
"""Denoising Autoencoder on Signal wave data.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lYSvcVwPE-ecG1NvwSwiiR8sss-N0-13
"""

!pip install tensorflow

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError

# Helper Function
def generate_wave_data(num_samples, sequence_length, noise_level=0.1):
    x = np.linspace(0, num_samples * np.pi, sequence_length)
    frequency = np.random.uniform(1, 100, 2)
    amplitudes = np.random.rand(2)
    signal = (amplitudes[0] * (frequency[0] * np.cos(2 * np.pi * x)) +
              amplitudes[1] * (frequency[1] * np.cos(2 * np.pi * x)))
    noise = noise_level * np.random.randn(sequence_length)
    signal += noise
    return signal

num_sequences = 1000
sequence_length = 256

all_signals = []
for i in range(num_sequences):
    wave = generate_wave_data(i, sequence_length)
    all_signals.append(wave)

data = np.array(all_signals)
data = data[:, :, np.newaxis]

plt.plot(data[0])
plt.title("noisy signal example")
plt.xlabel("time Step")
plt.ylabel("amplitude")
plt.show()

X_train, X_test = train_test_split(data, test_size=0.2, random_state=42)

input_layer = Input(shape=(sequence_length, 1))
x = Conv1D(16, kernel_size=3, activation='relu', padding='causal', dilation_rate=1)(input_layer)
x = MaxPooling1D(pool_size=2)(x)
x = Conv1D(32, kernel_size=3, activation='relu', padding='causal', dilation_rate=2)(x)
x = MaxPooling1D(pool_size=2)(x)
encoder_output = Conv1D(64, kernel_size=3, activation='relu', padding='causal', dilation_rate=4)(x)

x = UpSampling1D(size=2)(encoder_output)
x = Conv1D(32, kernel_size=3, activation='relu', padding='same')(x)
x = UpSampling1D(size=2)(x)
x = Conv1D(16, kernel_size=3, activation='relu', padding='same')(x)
decoder_output = Conv1D(1, kernel_size=3, activation='linear', padding='same')(x)

autoencoder = Model(input_layer, decoder_output)
autoencoder.compile(optimizer=Adam(0.001), loss='mse')

history = autoencoder.fit(
    X_train, X_train,
    epochs=30,
    batch_size=32,
    validation_data=(X_test, X_test),
    verbose=1
)

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title("training and validation loss")
plt.xlabel("epoch")
plt.ylabel("mse loss")
plt.legend()
plt.show()

predicted = autoencoder.predict(X_test)

n = 10
for i in range(n):
    plt.figure(figsize=(40, 4))
    plt.plot(X_test[i].squeeze(), label='noisy Input')
    plt.plot(predicted[i].squeeze(), label='denoised output')
    plt.title(f"signal {i+1}")
    plt.legend()
    plt.show()

mse = MeanSquaredError()
mae = MeanAbsoluteError()

total_mse = mse(X_test, predicted).numpy()
total_mae = mae(X_test, predicted).numpy()

print("mean squared error =", total_mse)
print("mean absolute error =", total_mae)